ğŸ§  EdTech Adaptive Learning Platform â€” Backend (FastAPI)
Welcome to the backend of the AI-driven EdTech Adaptive Learning Platform.
This system is designed to analyze student activity, evaluate answers, and provide AI-generated feedback, adaptive assessments, and chat-based course guidance using local Large Language Models (LLMs).

ğŸš€ Features
ğŸ“š Manage Courses and Lessons (CRUD)

ğŸ§  AI-Powered Feedback System (Answer Evaluation)

ğŸ’¬ Course-aware Chatbot (Ask about courses, topics, lessons)

ğŸ¤– Local LLM Integration via Ollama

ğŸ” JWT Authentication Ready

ğŸ› ï¸ Built with FastAPI, SQLAlchemy, SQLite, and Pydantic

âš™ï¸ System Requirements
Tool	Version	Required For
Python	3.10+	Backend server
pip	Latest	Installing Python dependencies
Git	Any	Cloning the project
Ollama	Latest	Local LLM inference

ğŸ“¦ Installation & Setup
1ï¸âƒ£ Clone the Repository

git clone https://github.com/your-username/edtech-backend.git
cd edtech-backend
2ï¸âƒ£ Set Up a Virtual Environment

# On Windows
python -m venv venv
venv\Scripts\activate

# On macOS/Linux
python3 -m venv venv
source venv/bin/activate
3ï¸âƒ£ Install Python Dependencies

pip install -r requirements.txt
4ï¸âƒ£ Install & Run Ollama with Gemma
We use Ollama to run LLMs locally (such as gemma) for AI feedback and chat.

âœ… Step-by-step:

# Download & install Ollama (choose your OS): https://ollama.com/download

# Pull the Gemma model
ollama pull gemma

# Run the model
ollama run gemma
By default, Ollama listens at:
http://localhost:11434

5ï¸âƒ£ Start the Backend Server

uvicorn app.main:app --reload
Server will start at:
ğŸ”— http://localhost:8000

ğŸ—‚ï¸ Project Structure

app/
â”œâ”€â”€ main.py                 # FastAPI entrypoint
â”œâ”€â”€ database.py             # DB setup (SQLAlchemy)
â”œâ”€â”€ models.py               # ORM models
â”œâ”€â”€ schemas.py              # Pydantic schemas
â”œâ”€â”€ llm_engine.py           # Ollama LLM integration
â”œâ”€â”€ ai_feedback.py          # AI Feedback logic
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ courses.py
â”‚   â”œâ”€â”€ lessons.py
â”‚   â””â”€â”€ chatbot.py
â””â”€â”€ ...
ğŸ” API Routes Overview
Endpoint	Description
GET /courses	List all courses
POST /courses	Create a new course
GET /courses/{id}/lessons	Get all lessons in a course
POST /courses/{id}/lessons	Add a lesson
POST /lessons/{id}/submit-answer	Get AI feedback on student answer
GET /chatbot?query=	Ask AI about course/lesson info

ğŸ¤– How It Works
Chat & Feedback prompts are sent from the frontend to the FastAPI server.

FastAPI sends these prompts to Ollama (Gemma) via HTTP.

Ollama returns generated responses, which are then displayed to users.